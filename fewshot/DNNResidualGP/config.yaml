#standard settings

epochs: 1
batch_size: 128
optimizer: Adam
lr: 0.0003
checkpoint_dir: checkpoint_dir/DNNResidualGP
val_freq: 1
num_workers: 0
lr_decay: 0.7
lr_step: 20

### DNNResidualGP-specific settings ###

#DNN hidden layers
hidden_layers: [128,32]
hidden_batchnorm: False

#GP learning parameters
#gp_k_shot: 10   #few-shot learning (DNNResidualFSGP)
#gp_loss: 'conditional' # 'marginal' or 'conditional' for few-shot learning
gp_lr: 0.1
gp_training_iter: 50
gp_kernel: 'RBFKernel'
#gp_kernel_independent_scaling: true #if true, each dimension of the input is scaled independently