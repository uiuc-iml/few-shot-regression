model: DNNResidualGP

#standard settings
epochs: 1
optimizer: Adam
batch_size: 64
lr: 0.0003
checkpoint_dir: checkpoint_dir/DNNResidualGP
val_freq: 1
num_workers: 8
lr_decay: 0.7
lr_step: 20

### DNNResidualGP-specific settings ###

#DNN hidden layers
hidden_layers: [64,32]
hidden_batchnorm: False

#GP learning parameters
#gp_k_shot: 10   #flat training
gp_lr: 0.1
gp_training_iter: 100 #50