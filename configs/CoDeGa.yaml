#standard settings
epochs: 100
zero_shot_batch_size: 128
adaptive_batch_size: 128
optimizer: Adam
dropout: 0 
checkpoint_dir: checkpoint_dir/CoDeGa
val_freq: 1
num_workers: 16
lr_decay: 0.9 
lr_step: 40 

#DNN hidden layers
hidden_layers: [16,8,4] 
hidden_batchnorm:  False
lr: 0.005
patience: 5 

#deep kernel parameters 
use_noise_constraint: False
CoDeGa_gp_training_epoch: 200
penalize_split_encoder: False
split_encoder_penalty: 1
##GP learning parameters
gp_k_shot: 10   #few-shot learning, should use the entire task's data
gp_kernel: 'RBFKernel'

### params deep kernel from scratch
gp_lr: 0.01 
gp_lr_decay: 1 
gp_lr_step: 20 

gp_input_dim: 4  
gp_layers:  [16,8]
gp_batchnorm: False

# Toy Gaussian
## manual splits
guided_splits: [[1, 8, 11, 12, 14, 16, 18, 19, 21, 23, 25, 27, 28, 32, 33, 35, 36, 38, 41, 44, 52],
                [55, 58, 60, 64, 66, 68, 69, 70, 71, 72, 73, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88],
                [27, 28, 32, 33, 35, 36, 38, 41, 44, 52, 55, 58, 60, 64, 66, 68, 69, 70, 71, 72, 73]]





